---
layout: post
title: "Day 5 - Finishing My Final Quest"
---

### What I Set Out to Do
On this day of my project, I planned to finish my Final Quest by completing the data science microproject about making AI scene recognition model. 

---

### What I Actually Did

I built my classifier function, using the video frames' pixel color data (in the form of RGB) to distinguish between video frames representing the setting of the lecture, the notebook used during the video, and an "other" category. Since each category of video frames showed a consistent pattern in their pixel color data (e.g., notebook scenes had RGBs very close to 255), I used conditionals to check if a given video frame is one of those categories. Then, I ran my function for all the video frames of that lecture (about 330) and put that information and the outputs of the function in a data frame.

---

### What I Learned or Noticed

I learned the syntax to load visual data from a video frame, to find the average color of a single frame, and to find the individual average colors. Doing this, I also learned how pixel colors are stored in RGB; there are three numbers between 0 and 255 representing red, green, and blue, respectively. The higher the number, the more of that color is present in the image.

---

### What's Next

Both of my data science microprojects could be taken a step further. In my FIFA matches data project, I could make differnet data visualizations for statistics I have not accounted for. For example, I can create a world map that shows the geographic distribution of all international matches in FIFA history. In my scene recognition microproject, I can expand my classifier function by including more categories from within the "other" category. For example, there is a group of data frames that represent the credits of the video. I could use their image pixel color data (their RGBs are common; all of them are a bit over 0) to identify them in my classifier function.
